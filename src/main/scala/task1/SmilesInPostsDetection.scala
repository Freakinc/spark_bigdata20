package task1

import org.apache.spark.broadcast.Broadcast
import org.apache.spark.sql.SparkSession
/*
Ð°Ð¹Ñ‚Ð¸ ÑÐ¼Ð°Ð¹Ð»Ð¸ÐºÐ¸ Ð² Ð¿Ð¾ÑÑ‚Ð°Ñ… Ð¸ ÐºÐ¾Ð¼Ð¼ÐµÐ½Ñ‚Ð°Ñ€Ð¸ÑÑ… Ðº Ð¿Ð¾ÑÑ‚Ð°Ð¼ (Ð½ÐµÐ³Ð°Ñ‚Ð¸Ð²Ð½Ñ‹Ðµ, Ð¿Ð¾Ð·Ð¸Ñ‚Ð¸Ð²Ð½Ñ‹Ðµ, Ð½ÐµÐ¹Ñ‚Ñ€Ð°Ð»ÑŒÐ½Ñ‹Ðµ)
(Ð¼Ð¾Ð¶ÐµÑ‚Ðµ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÑŒ Ð²Ð½ÐµÑˆÐ½Ð¸Ðµ Ð±Ð¸Ð±Ð»Ð¸Ð¾Ñ‚ÐµÐºÐ¸ Ð¸Ð»Ð¸ Ð¿Ñ€ÐµÐ´Ð¾Ð¿Ñ€ÐµÐ´ÐµÐ»ÐµÐ½Ð½Ñ‹Ðµ ÑÐ¿Ð¸ÑÐºÐ¸ ÑÐ¼Ð°Ð¹Ð»Ð¸ÐºÐ¾Ð²)
(Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐ¹Ñ‚Ðµ Ñ„ÑƒÐ½ÐºÑ†Ð¸ÑŽ spark udf Ð¸ broadcast Ð´Ð»Ñ ÑÐ¼Ð°Ð¹Ð»Ð¸ÐºÐ¾Ð²
 */
object SmilesInPostsDetection {
  def main(args: Array[String]): Unit = {
    val sparkSession = SparkSession.builder().appName("task1_smilesInPostsDetection").master("local[*]").getOrCreate()

    val sc = sparkSession.sparkContext
    import sparkSession.implicits._

    val smiles = Map(
                     ("\uD83D\uDE21" -> "neg"), //      ðŸ˜¡
                     ("\uD83E\uDD2C" -> "neg"), //      ðŸ¤¬
                     ("\uD83D\uDE0A" -> "pos"), //      ðŸ˜Š
                     ("\uD83D\uDE02" -> "pos"), //      ðŸ˜‚
                     ("\uD83D\uDE10" -> "neu"), //      ðŸ˜
                     ("\uD83D\uDE05" -> "neu")) //      ðŸ˜…

    val broadCastDictionary = sc.broadcast(smiles)

    val pos_group_count = sc.accumulator(0)
    val neg_group_count = sc.accumulator(0)
    val neu_group_count = sc.accumulator(0)

    val group_posts = sparkSession.read
      .json("data/posts_api.json")
      .select("key", "text")
      .filter(row => row.get(1) != "")

    group_posts.foreach(row => {
      if (!row.isNullAt(1)) {
        val line = row.get(1).toString
        val words = line.split(" ").toList
        val temp = words.map(word => getElementsCount(word, broadCastDictionary))
        temp.foreach(row => {
          row._1 match {
            case "pos" => pos_group_count += row._2
            case "neg" => neg_group_count += row._2
            case "neu" => neu_group_count += row._2
            case _ => ""
          }
        })
      }
    })

    val pos_followers_count = sc.accumulator(0)
    val neg_followers_count = sc.accumulator(0)
    val neu_followers_count = sc.accumulator(0)

    val followers_posts = sparkSession.read
      .json("data/followers_posts_api_final.json")
      .select("key", "text")
      .filter(row => row.get(1) != "")

    followers_posts.foreach(row => {
      if (!row.isNullAt(1)) {
        val str = row.get(1).toString
        val words = str.split(" ").toList
        val temp = words.map(word => getElementsCount(word, broadCastDictionary))
        temp.foreach(row => {
          row._1 match {
            case "pos" => pos_followers_count += row._2
            case "neg" => neg_followers_count += row._2
            case "neu" => neu_followers_count += row._2
            case _ => ""
          }
        })
      }
    })

    val result = Seq(
      ("Group posts", pos_group_count.value, neg_group_count.value, neu_group_count.value),
      ("Followers posts", pos_followers_count.value, neg_followers_count.value, neu_followers_count.value)
      ).toDF("from", "pos", "neg", "neu")

    result.write.json("results/task1/smiles_in_posts_detection")

  }

  private def getElementsCount(word: String, dict: Broadcast[Map[String, String]]): (String, Int) = {
    dict.value
      .filter { case (wording, wordType) => wording.equals((word)) }
      .map(x => (x._2, 1))
      .headOption
      .getOrElse(("undefined" -> 1))
  }
}
